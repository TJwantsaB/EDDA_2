---
title: "Assignment 2"
author: "Lukas Unruh, Teije Langelaan, Gidon Quint"
date: "`r format(Sys.Date(), '%d %B, %Y')`"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
set.seed(333)
library(lme4)
library(Matrix)
library(carData)
library(ggplot2)
options(digits=3)
```

# Exercise 1

```{r}
fruitfly_data=read.table(file="fruitflies.txt",header=TRUE)
```

## Lukas)

### a)

### b)

### c)

### d)

### e)

## Gid)

```{r}
fruitfly_data=read.table(file="fruitflies.txt",header=TRUE)
```

### a)

```{r}
head(fruitfly_data)
fruitfly_data$loglongevity = log(fruitfly_data$longevity)
head(fruitfly_data)

par(mfrow = c(2, 3))

for (activity_level in unique(fruitfly_data$activity)) {
  data_subset = subset(fruitfly_data, activity == activity_level)$loglongevity
  
  qqnorm(data_subset, main = paste("Q-Q plot -", activity_level))
  qqline(data_subset)
  
  hist(data_subset, main = paste("Histogram -", activity_level), xlab = "Log(Longevity)", breaks = 20)
  
  shapiro_test = shapiro.test(data_subset)
  cat("Shapiro-Wilk test for", activity_level, "activity: p-value =", shapiro_test$p.value, "\n")
}

boxplot(loglongevity ~ activity, data = fruitfly_data, main = "Log(Longevity) by Activity Level", xlab = "Activity Level", ylab = "Log(Longevity)")

kruskal.test(loglongevity ~ activity, data = fruitfly_data)

aggregate(loglongevity ~ activity, data = fruitfly_data, FUN = median)

```

The aggregate function's output shows the median log-longevity for each activity group: isolated flies have the highest median log-longevity (4.13), followed by those with low sexual activity (4.03), and flies with high sexual activity have the lowest median log-longevity (3.69). This suggests that increased sexual activity may be associated with decreased longevity in fruit flies

### b)

I do linear regression although we would need normality. However because we use the loglongevity the use of linear regression is fine

```{r}
multireg_model = lm(loglongevity ~ activity + thorax, data = fruitfly_data)
summary(multireg_model)

qqnorm(residuals(multireg_model))
qqline(residuals(multireg_model))
plot(fitted(multireg_model), residuals(multireg_model))
abline(h = 0)
```

This shows that the residuals deviade from normality. Especially at the tails. The plot of fitted values against residuals does not show a clear pattern, which is good as it suggests homoscedasticity (constant variance of the residuals across the range of fitted values). There is no apparent funnel shape or systematic pattern, which is indicative of potential issues with variance.

because the Q-Q plot does show some deviation from normality, it could be beneficial to either transform the data to achieve normality or use a robust regression method that is less sensitive to non-normality.

activityisolated and activitylow are both positive, with isolated having a larger coefficient than low. Showing that compared to high sexual activity, being isolated is associated with an increase in log-longevity (which translates to an increase in actual longevity), while low sexual activity is also associated with an increase in log-longevity but to a lesser extent than isolation. Therefore, sexual activity appears to decrease longevity compared to no activity, with higher activity decreasing it more.

```{r}

average_thorax = mean(fruitfly_data$thorax)

new_data = expand.grid(activity = unique(fruitfly_data$activity), thorax = average_thorax)

new_data$predicted_loglongevity = predict(multireg_model, newdata = new_data)

new_data$predicted_longevity = exp(new_data$predicted_loglongevity)

print(new_data)


```

### c)

```{r}
ggplot(fruitfly_data, aes(x = thorax, y = loglongevity, color = activity)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Relationship between Thorax Length and Log(Longevity) by Activity Group",
       x = "Thorax Length",
       y = "Log(Longevity)")

# added interaction between thorax and activity for regression model
interaction_model = lm(loglongevity ~ thorax * activity, data = fruitfly_data)
summary(interaction_model)


qqnorm(residuals(interaction_model))
qqline(residuals(interaction_model))

plot(fitted(interaction_model), residuals(interaction_model))
abline(h = 0)

```

The scatter plot with regression lines shows a positive relationship between thorax length and log longevity. The slopes of the lines appear to differ between groups, suggesting that the rate of increase in longevity with thorax length may vary by sexual activity level.

The regression analysis suggests that thorax length positively affects longevity in fruit flies, with the effect being less for flies with higher sexual activity. The interaction between thorax length and isolated sexual activity is marginally (0.55) significant, indicating a possible difference in this effect between flies with no sexual activity and those with high sexual activity.

GPT GENERATED

The regression analysis conducted so far has shown that there is a significant interaction between thorax length and the isolated group of fruit flies, suggesting that the dependence of longevity on thorax length differs when flies are kept in isolation compared to those with high sexual activity. For flies with low sexual activity, however, the interaction was not statistically significant, indicating that their longevity dependence on thorax length does not differ much from flies with high sexual activity. This suggests that the influence of thorax length on longevity is not consistent across all conditions of sexual activity.

### d)

Model c) has a slightly higher adjusted R-squared value (0.709 compared to 0.717) and these additional explanatory variables are significant (as seen in the interaction term with p = 0.055), this suggests that model c) is potentially better at explaining the variability in the response, despite being more complex. Another point worth mentioning is that thorax length allows for a more nuanced interpretation of the data, acknowledging the biological reality that physical traits can affect longevity. However neither is necessarily "wrong".

Normally we would say that model b) is better because it has about the same R2 and it has less variables however thorax!


### e)

```{r}

# this plot as it is done in the lecture but there are probably better ways to do it
plot(longevity ~ thorax, data = fruitfly_data, pch = as.character(fruitfly_data$activity),
     main = "Longevity vs Thorax Length by Activity Level",
     xlab = "Thorax Length", ylab = "Longevity")



fruitfly_data$activity = as.factor(fruitfly_data$activity)

ancova_model = lm(longevity ~ activity + thorax, data = fruitfly_data)

summary(ancova_model)

anova(ancova_model)

drop1(ancova_model, test = "F")



```

The ANCOVA with raw longevity data has a slightly lower adjusted R-squared compared to the model with log-transformed longevity, which suggests that the log transformation may provide a better fit. The choice of using the log of longevity as the response variable likely helped to stabilize variance and linearize the relationship between predictors and longevity, making it a wise choice for the analysis.

## TJ)

### a)

### b)

### c)

### d)

### e)

# Exercise 2

```{r}
birthweight_data=read.csv(file="Birthweight.csv",header=TRUE)

```

In our data set we have multiple continuous and discrete variables. However, for the model we do not have to state that discrete variables are factors as all of them only have 2 levels (no = 0 and yes = 1). \## Lukas)

### a)

### b)

### c)

### d)

### e)

### f)

### g)

### h)

### i)

## Gid)

```{r}
birthweight_data=read.csv(file="Birthweight.csv",header=TRUE)

```

### a)

```{r}
full_model = lm(Birthweight ~ Length + Headcirc + Gestation + mage + mnocig + 
                mheight + mppwt + fage + fedyrs + fnocig + fheight, data = birthweight_data)

cooksD = cooks.distance(full_model)

plot(cooksD, type = "h", main = "Cook's Distance Plot", ylab = "Cook's Distance")
abline(h = 1, col = "red")
```
There is not a single value with a Cook's Distance higher then 1, so we conclude that there is no influence point.
#### Question: Can we conclude that there is no influence point? Or is it the same with H0 and H1 and we can only conclud H1 if influence point. Think of the normality question in Shapiro Wilk test.

```{r}
library(car)

# this is what they do in the slides but with so many variables not that nice...
pairs(~ Length + Headcirc + Gestation + mage + mnocig + mheight + mppwt + fage + fedyrs + fnocig + fheight, data = birthweight_data)

cor(birthweight_data[,c("Length", "Headcirc", "Gestation", "mage", "mnocig", "mheight", "mppwt", "fage", "fedyrs", "fnocig", "fheight")])

vif_values = vif(full_model)

high_vif = vif_values[vif_values > 5]
if(length(high_vif) > 0) {
  print(high_vif)
} else {
  print("No value is higher than 5")
}
```
The correlation and VIF analysis for the Birthweight dataset indicates moderate collinearity among predictors, with no VIF values exceeding the threshold of 5, suggesting that while relationships exist, they may not significantly impair the regression model's effectiveness.

### b)

#### Question: Shouldnt we delete the coulomn lowbwt? As that should always have an effect on birthweight

```{r}
reduced_model <- step(full_model, direction="backward")

summary(reduced_model)
```
We deleted fage, mheight, fedyrs, fnocig, mnocig and mage in this order. Resulting in a model: Birthweight ~ Length + Headcirc + Gestation + mage + mppwt + fheight

#### To me it looks like this doesnt work So I do it again but manually
```{r}
summary(full_model)
summary(lm(Birthweight ~ Length + Headcirc + Gestation + mage + mnocig + mheight + mppwt + fedyrs + fnocig + fheight, data = birthweight_data))
summary(lm(Birthweight ~ Length + Headcirc + Gestation + mage + mnocig + mppwt + fedyrs + fnocig + fheight, data = birthweight_data))
summary(lm(Birthweight ~ Length + Headcirc + Gestation + mage + mnocig + mppwt + fnocig + fheight, data = birthweight_data))
summary(lm(Birthweight ~ Length + Headcirc + Gestation + mage + mppwt + fheight, data = birthweight_data))
summary(lm(Birthweight ~ Headcirc + Gestation + mage + mppwt + fheight, data = birthweight_data))
summary(lm(Birthweight ~ Headcirc + Gestation + mage + mppwt, data = birthweight_data))
summary(lm(Birthweight ~ Headcirc + Gestation + mppwt, data = birthweight_data))
final_model = lm(Birthweight ~ Headcirc + Gestation, data = birthweight_data)
summary(final_model)
```
This way we end up with a completely significant model however only with Headcirc and Gestation. 

```{r}
residuals = residuals(final_model)

par(mfrow = c(1, 3))
boxplot(residuals, main = "Boxplot of Residuals", ylab = "Residuals", xlab = "Index")
qqnorm(residuals, main = "Q-Q Plot of Residuals")
qqline(residuals, col = "red")
hist(residuals, main = "Histogram of Residuals", xlab = "Residuals", breaks = 20)

shapiro.test(residuals)
```
From the shapiro wilk test we cannot conclude that the residuals are not normally distribtuted, however after taking a good look ath the QQ plot and the histoplot we conclude that our residuals are not normally distributed.


### c)
#### Remark. I dont understand these formulas: 
Now we are left with two different models.
Model 1 with R
2 = 0.771 and σˆ = 2.51:
Fat = -23.6345 + 0.8565*Thigh + error
Model 2 with R
2 = 0.7862 and σˆ = 2.496:
Fat = 6.7916 + 1.0006*Triceps -0.4314*Midarm + error

Slide 10 of lecture 8

```{r}
fitted_values = fitted(final_model)
print(fitted_values)

average_values = data.frame(
  Headcirc = mean(birthweight_data$Headcirc, na.rm = TRUE),
  Gestation = mean(birthweight_data$Gestation, na.rm = TRUE)
)

confidence_intervals = predict(final_model, newdata = average_values, interval = "confidence", level = 0.95)

prediction_intervals = predict(final_model, newdata = average_values, interval = "prediction", level = 0.95)

print("95% Confidence Intervals for the Mean Response:")
print(confidence_intervals)
print("95% Prediction Intervals for a New Observation:")
print(prediction_intervals)
```
The output indicates that for babies with average head circumference and gestation, the model predicts a mean Birthweight of 3.31 kg, with a 95% confidence interval of 3.21 to 3.42 kg for the mean and a wider 95% prediction interval of 2.61 to 4.02 kg for individual observations, reflecting the increased uncertainty in predicting specific outcomes.

### d)

```{r}
library(glmnet)

x=as.matrix(birthweight_data[,-3])
y=as.double(as.matrix(birthweight_data[,3]))

train_indices = sample(1:nrow(x), 0.67 * nrow(x))
x.train = x[train_indices,]
y.train = y[train_indices]
x.test = x[-train_indices,]
y.test = y[-train_indices]

lasso_mod = glmnet(x.train, y.train, alpha = 1)

cv_lasso = cv.glmnet(x.train, y.train, alpha = 1, type.measure = 'mse')

plot(lasso_mod, label = TRUE, xvar = "lambda")
plot(cv_lasso)

lambda.min = cv_lasso$lambda.min
lambda.1se = cv_lasso$lambda.1se

best_coefs = coef(lasso_mod, s = lambda.min)

y.pred = predict(lasso_mod, s = lambda.min, newx = x.test)

mse_lasso = mean((y.test - y.pred)^2)

print(list(lambda.min = lambda.min, lambda.1se = lambda.1se))
print(best_coefs)
print(mse_lasso)

```

##### I am sorry I really looked but didnt know how to compare or comment. I am not too sure what to do here

### e)

```{r}
filtered_data = birthweight_data[, c("lowbwt", "Gestation", "smoker", "mage35")]

table(smoker = filtered_data$smoker, lowbwt = filtered_data$lowbwt)
table(mage35 = filtered_data$mage35, lowbwt = filtered_data$lowbwt)


# For smoking mothers
boxplot(Birthweight ~ smoker, data=birthweight_data, main="Birthweight by Smoking Status", xlab="Smoker", ylab="Birthweight")

# For mothers over 35
boxplot(Birthweight ~ mage35, data=birthweight_data, main="Birthweight by Mother's Age", xlab="Mother age > 35", ylab="Birthweight")

```

The data indicates that smoking mothers have a higher proportion of babies with low birth weight compared to non-smoking mothers, while there is no clear trend observed in the birth weight concerning the mother's age being above 35.
However as seen in the tables, some combinations of low birth weight and smoking or mothers age above 35 have a prevalence of 1. So the power of this effect is only an estimate and very weak.  

### f)

```{r}
logistic_model = glm(lowbwt ~ Gestation + smoker + mage35, family = binomial, data = birthweight_data)

summary(logistic_model)
```

The logistic regression results show that increased gestation significantly decreases the odds of low birth weight (which aligns with medical expectations that longer gestation leads to higher birth weight as shown above), while the effects of smoking and maternal age over 35 are positive but not statistically significant, indicating limited evidence of their influence within this dataset.

### g)

```{r}
model_gestation_smoker = glm(lowbwt ~ Gestation * smoker, data = birthweight_data, family = binomial)

anova(model_gestation_smoker, test = "Chisq")

model_gestation_mage35 = glm(lowbwt ~ Gestation * mage35, data = birthweight_data, family = binomial)

anova(model_gestation_mage35, test = "Chisq")

```

Note for later this was in the slide: H0 : β1 = β2 = β3 = β4 is not rejected

For both the smoker and mothers age above 35 we do not reject the H0 as the interactions are both not significant. 


##### Regarding the choosing of the correct model I dont know sorry

### h)

```{r}
new_data <- data.frame(Gestation = rep(40, 4),
                       smoker = c(0, 1, 0, 1),
                       mage35 = c(0, 0, 1, 1))

probabilities <- predict(logistic_model, newdata = new_data, type = "response")

print(probabilities)
```

### i)

```{r}
# For smoker vs. lowbwt
table_smoker = table(birthweight_data$smoker, birthweight_data$lowbwt)
chi2_test_smoker = chisq.test(table_smoker)
print(chi2_test_smoker)

# For mage35 vs. lowbwt
table_mage35 = table(birthweight_data$mage35, birthweight_data$lowbwt)
chi2_test_mage35 = chisq.test(table_mage35)
print(chi2_test_mage35)

```

And advantage is it's straightforward and doesn't assume a specific form for the relationship between variables, making it ideal for initial exploration of associations between categorical variables.
A disadvantage is it lacks the ability to adjust for other variables or to easily interpret effects in terms of odds ratios, which logistic regression provides.
Also very low sample size for some groups so the chisquare test is very unreliable in this case.


## TJ)

### a)

```{r}
# Assuming birthweight_data is your dataset
summary(birthweight_data)

# Fit a linear model
TJ_BW <- lm(Birthweight ~ Length + Headcirc + Gestation + mage + mnocig + mheight + mppwt + fage + fedyrs + fnocig + fheight, data=birthweight_data)

# Plot diagnostics for influential points
par(mfrow=c(2,2))
plot(TJ_BW, which=1:4) # Plots for residuals, leverage, etc.
round(cooks.distance(TJ_BW),2)


```

Upon inspection of Cook's distances, we conclude that there are no influence points in the data set, as no observation has a Cook's distance greater than 1.

```{r}
predictors <- birthweight_data[, c("Length", "Headcirc", "Gestation", "mage", "mnocig", "mheight", "mppwt", "fage", "fedyrs", "fnocig", "fheight")]
print(cor(predictors))
library(carData)
vif_values <- vif(TJ_BW)
print(vif_values)
```

Upon inspection of correlation matrix, we note that variables mage and fage appear to be highly correlated (0.806), however their VIF values are under 5, therefore we conclude that the model has no problem of collinearity.

### b)

```{r}
summary(TJ_BW)
TJ_BW_reduced <- step(TJ_BW, direction = "backward")
summary(TJ_BW_reduced)
```

Using the step-down approach we arrived at the following model: Birthweight \~ Length + Headcirc + Gestation + mage + mppwt + fheight with R-squared: 0.757

```{r}
plot(TJ_BW_reduced, which = 1)

qqnorm(residuals(TJ_BW_reduced))
qqline(residuals(TJ_BW_reduced))
shapiro.test(residuals(TJ_BW_reduced))
```

In the residuals vs fitted plot, the pattern from 3.0 to 3.5 could hint at non-linearity, adding polynomial or interaction terms might improve fit. Upon further inspection of the QQ-plot and shapiro-Wilk test we conclude that the assumption of normally distributed residuals is not met.

### c)

```{r}
# Calculate the average values for the predictors
avg_data <- data.frame(
  Length = mean(birthweight_data$Length, na.rm = TRUE),
  Headcirc = mean(birthweight_data$Headcirc, na.rm = TRUE),
  Gestation = mean(birthweight_data$Gestation, na.rm = TRUE),
  mage = mean(birthweight_data$mage, na.rm = TRUE),
  mppwt = mean(birthweight_data$mppwt, na.rm = TRUE),
  fheight = mean(birthweight_data$fheight, na.rm = TRUE)
)

# Assuming your model is named 'TJ_BW_reduced' and is already fitted with the correct formula
# Predict the Birthweight for the average values with 95% confidence interval
confidence_interval <- predict(TJ_BW_reduced, newdata = avg_data, interval = "confidence", level = 0.95)

# Predict the Birthweight for the average values with 95% prediction interval
prediction_interval <- predict(TJ_BW_reduced, newdata = avg_data, interval = "prediction", level = 0.95)

# View the results
confidence_interval
prediction_interval
```

### d)

```{r}
library(glmnet)
set.seed(3)
x=as.matrix(birthweight_data[,-3]) #remove the response variable
y=as.double(as.matrix(birthweight_data[,3])) #only the response variable
train=sample(1:nrow(x),0.67*nrow(x)) # train by using 2/3 of the data
x.train=x[train,]; y.train=y[train] # data to train
x.test=x[-train,]; y.test=y[-train] # data to test the prediction quality
lasso.mod=glmnet(x.train,y.train,alpha=1)
cv.lasso=cv.glmnet(x.train,y.train,alpha=1,type.measure="mse")
plot(lasso.mod,label=T,xvar="lambda") #have a look at the lasso path
plot(cv.lasso) # the best lambda by cross-validation
lambda.min=cv.lasso$lambda.min; lambda.1se=cv.lasso$lambda.1se
coef(lasso.mod,s=cv.lasso$lambda.1se) #beta’s for the best lambda
y.pred=predict(lasso.mod,s=lambda.1se,newx=x.test) #predict for test
mse.lasso=mean((y.test-y.pred)^2) #mse for the predicted test rows
```

Lasso model: Birthweight \~ Length + Headcirc + Gestation + lowbwt Step down: Birthweight \~ Length + Headcirc + Gestation + mage + mppwt + fheight

The Lasso model and the step-down method both identify Length, Head Circumference, and Gestation as significant predictors of Birthweight, indicating their critical role. The Lasso model is more parsemonious, using two fewer variables. It uniquely includes lowbwt, a binary variable distinguishing between birth weights below and above 6 pounds, which the step-down model omits. Conversely, the step-down model retains mage, mppwt, and fheight, suggesting these factors may have some predictive value not captured by the Lasso model, likely due to its penalty on model complexity that excludes less impactful variables.

### e)

```{r}
boxplot(birthweight_data$Birthweight ~ birthweight_data$smoker, main = "Birthweight by Smoking Status", xlab = "Smoker", ylab = "Birthweight")
boxplot(birthweight_data$Birthweight ~ birthweight_data$mage35, main = "Birthweight by Mother's Age", xlab = "Mother aged 35+", ylab = "Birthweight")
barplot(table(birthweight_data$lowbwt, birthweight_data$smoker), beside = TRUE, main = "Low Birthweight by Smoking Status", xlab = "Smoker", ylab = "Count", names.arg = c("No", "Yes"), legend = TRUE)
legend("topright", legend = c("No", "Yes"), 
       fill = c("black", "grey"), 
       title = "Low birthweight")
barplot(table(birthweight_data$lowbwt, birthweight_data$mage35), beside = TRUE, main = "Low Birthweight by Mother's Age", xlab = "Mother aged 35+", ylab = "Count", names.arg = c("No", "Yes"), legend = TRUE)
legend("topright", legend = c("No", "Yes"), 
       fill = c("black", "grey"), 
       title = "Low birthweight")
table(birthweight_data$smoker, birthweight_data$lowbwt)
table(birthweight_data$mage35, birthweight_data$lowbwt)


```

The boxplot do not show a clear difference in birthweight resulting from the varibales 'smoker' and 'mage35'. Both the bar graph, and contingency table do suggests a potential influence of smoking on low birthweight. The limited sample sizes \<5 for some experimental units, hinder us in getting reliable chi-squared results on these possible effects.

### f)

```{r}
TJ_LOWBWT <- glm(lowbwt ~ Gestation + mage35 + smoker, data = birthweight_data, family = binomial)
summary(TJ_LOWBWT)
exp(coef(TJ_LOWBWT))

```

Upon analyzing the logistic regression summary, it is observed that 'gestation' significantly affects 'lowbwt' (p=0.029), indicating a statistically significant impact on low birthweight, whereas 'smoker' and 'mage35' do not show a statistically significant effect. However, the reliability of these findings is questioned due to insufficient sample sizes in groups with fewer than five observations. Despite this, the odds ratios suggest notable effects: 'gestation' has an odds ratio of 0.231 indicating a lower likelihood of low birthweigt for later weeks of gestation, 'smoking' has an odds ratio of 233, indicating a much higher likelihood of low birthweight among smokers, while 'mage35' shows a 38% increased odds for older mothers. These findings, highlight health risks but require larger studies for validation due to the current sample limitations, in particalarly for the effect of smoking.

### g)

```{r}
# Model with Gestation * smoker interaction
TJ_LOWBWT_GestSmoker <- glm(lowbwt ~ mage35 +Gestation * smoker, data = birthweight_data)
summary(TJ_LOWBWT_GestSmoker)
exp(coef(TJ_LOWBWT_GestSmoker))

# Model with Gestation * mage35 interaction
TJ_LOWBWT_GestMage35 <- glm(lowbwt ~ smoker +Gestation * mage35, data = birthweight_data)
summary(TJ_LOWBWT_GestMage35)
exp(coef(TJ_LOWBWT_GestMage35))
```

Upon inspection of the two models, we pick the first one with the interaction of 'gestation' and 'smoking' since it yielded significant results for the interaction between the two factors. Interestingly the effect of 'gestation' in this model decreased, probably because a big part of its effect in the additive model is now better explained by its interaction with 'smoking'

### h)

The resulting model = lowbwt ~ Gestation + smoker + Gestation:smoker

```{r}
# Assuming the model is stored in model_g
model_g <- glm(lowbwt ~ Gestation + smoker + Gestation:smoker, data = birthweight_data)

# New data frame for prediction at 40 weeks
new_data <- data.frame(Gestation = c(40, 40),
                       smoker = c(0, 1))

# Predict probabilities using the model
probabilities <- predict(model_g, newdata = new_data, type = "response")

# Print the probabilities for non-smokers and smokers
print(probabilities)

# No need to convert to odds if you're interested in probabilities

```
For babies born at 40 weeks of gestation, the predicted probability of low birth weight is 2.62% for non-smokers and 10.51% for smokers, highlighting the significant impact of maternal smoking on birth weight outcomes. This underscores the importance of smoking cessation interventions during pregnancy to mitigate the risk of low birth weight.

### i)

```{r}
contingency_table <- table(birthweight_data$lowbwt, birthweight_data$smoker)
chi_squared_result <- chisq.test(contingency_table)
print(chi_squared_result)
```
This approach is not wrong, however as mentioned before, the sample sizes in some of the experimental units are not large enough <5. Making the chi-squared results unreliable and incorrect. If we would have a larger sample, chi-squared would work. The advantage of chi-squared is its simplicity, however nuances such as the interaction we found between 'smoking' and 'gestation' would not have been found by only using chi-squared. So it has the caveat of possibly overlooking important nuances.

# Exercise 3

```{r}
awards_data=read.table(file="awards.txt",header=TRUE)
```

## Lukas)

### a)

### b)

### c)

## Gid)

### a)

### b)

### c)

## TJ)

### a)

### b)

### c)
